gam.mod1 <- gam(activity.level~claw.width + carapace.width + toadfish.cue.treatment, family = binomial, random = list(ID=~ 1), data = df)
summary(gam.mod1)
#Interactive Effect
gam.mod2 <- gam(activity.level~claw.width * carapace.width * toadfish.cue.treatment, family = binomial, random = list(ID=~ 1), data = df)
summary(gam.mod2)
#Interactive Effect
gam.mod2 <- gam(activity.level~claw.width * carapace.width * toadfish.cue.treatment, family = binomial, random = list(ID=~ 1), data = df)
summary(gam.mod2)
AIC(gam.mod1, gam.mod2)
# (Q5) - Based on the residuals of your generalized additive models, how confident are you in these results? (2 pts)
plot(gam.mod1$residuals, ylim = c(-.1,.1))
# (Q5) - Based on the residuals of your generalized additive models, how confident are you in these results? (2 pts)
plot(gam.mod1$residuals, ylim = c(-.1,.1))
plot(gam.mod2$residuals, ylim = c(-.1,.1))
# (Q5) - Based on the residuals of your generalized additive models, how confident are you in these results? (2 pts)
plot(gam.mod1$residuals, ylim = c(-.1,.1))
plot(gam.mod2$residuals, ylim = c(-.1,.1))
df
#Additive Effects
glmm.mod1 <- glmmPQL(activity.level~claw.width + carapace.width + toadfish.cue.treatment, family = binomial, random = ~ 1 | ID, data = df)
summary(glmm.mod1)
#Interactive Effect
glmm.mod2 <- glmmPQL(activity.level~claw.width + carapace.width * toadfish.cue.treatment, family = binomial, random = ~ 1 | ID, data = df)
summary(glmm.mod2)
df <- read.csv("Uchidaetal_2019_Data.csv")
setwd("C:/GitHub/R4Eco_2022/Week6")
df <- read.csv("Uchidaetal_2019_Data.csv")
# Take a look and see what our data look like this week:
head(df)
# To start, we are going to use a assume a normal (aka Gaussian) distribution because we are using a linear model:
# The argument "random = ~ 1 | ID" is used to specify individual as a random effect.
# The "~ 1 |" notation is common across model functions to signify a random effect.
# The 'family' argument is used to specify the distribution family.
# Options for this can be found by looking up ?family.
# Otherwise this function should look very similar to the arguments in the lm() function for fixed effects.
glmm.mod <- glmmPQL(Flight.initiation.distance..FID.~Object, family = gaussian, random = ~ 1 | ID, data = df)
df
head(df)
#Additive Effects
glmm.mod1 <- glmmPQL(activity.level~claw.width + carapace.width + toadfish.cue.treatment, family = binomial, random = ~ 1 | ID, data = df)
summary(glmm.mod1)
#Additive Effects
glmm.mod1 <- glmmPQL(activity.level~claw.width + carapace.width + toadfish.cue.treatment, family = binomial, random = ~ 1 | ID, data = df)
# The authors used proportional consumption of prey as the (y) in their model, but did not include this in the dataset.
# So we are going to create it - run the following line, assuming df= your data frame (feel free to change that):
df$prop.cons <- df$eaten/df$prey
df <- read.csv(file=("C:/GitHub/morgan/Week 6/Toscano_Griffen_Data.csv"), header=T)
df
head(df)
#Additive Effects
glmm.mod1 <- glmmPQL(activity.level~claw.width + carapace.width + toadfish.cue.treatment, family = binomial, random = ~ 1 | block, data = df)
library(MASS)
library (MuMIn)
library(mgcv)
#Additive Effects
glmm.mod1 <- glmmPQL(activity.level~claw.width + carapace.width + toadfish.cue.treatment, family = binomial, random = ~ 1 | block, data = df)
summary(glmm.mod1)
r.squaredGLMM(glmm.mod1)
r.squaredGLMM(glmm.mod1)
#Interactive Effect
glmm.mod2 <- glmmPQL(activity.level~claw.width + carapace.width * toadfish.cue.treatment, family = binomial, random = ~ 1 | block, data = df)
summary(glmm.mod2)
# The authors used proportional consumption of prey as the (y) in their model, but did not include this in the dataset.
# So we are going to create it - run the following line, assuming df= your data frame (feel free to change that):
df$prop.cons <- df$eaten/df$prey
# (Q3) - Plot the residuals of both models. Do you think either model is a good fit? Why or why not? (3 pts)
plot(glmm.mod1$residuals, ylim = c(-.1,.1))
plot(glmm.mod2$residuals, ylim = c(-.1,.1))
#Additive Effects
glmm.mod1 <- glmmPQL(activity.level~claw.width + carapace.width + toadfish.cue.treatment, family = binomial, random = ~ 1 | block, data = df)
summary(glmm.mod1)
#Interactive Effect
glmm.mod2 <- glmmPQL(activity.level~claw.width + carapace.width * toadfish.cue.treatment, family = binomial, random = ~ 1 | block, data = df)
summary(glmm.mod2)
df
#Additive Effects
glmm.mod1 <- glmmPQL(activity.level~claw.width + carapace.width + toadfish.cue.treatment, family = binomial, random = ~ 1 | block, data = df)
summary(glmm.mod1)
#Interactive Effect
glmm.mod2 <- glmmPQL(activity.level~claw.width * carapace.width + toadfish.cue.treatment, family = binomial, random = ~ 1 | block, data = df)
summary(glmm.mod2)
library(MASS)
library (MuMIn)
library(mgcv)
df <- read.csv(file=("C:/GitHub/morgan/Week 6/Toscano_Griffen_Data.csv"), header=T)
df
head(df)
#Additive Effects
glmm.mod1 <- glmmPQL(activity.level~claw.width + carapace.width + toadfish.cue.treatment, family = binomial, random = ~ 1 | block, data = df)
summary(glmm.mod1)
#Interactive Effect
glmm.mod2 <- glmmPQL(activity.level~claw.width * carapace.width + toadfish.cue.treatment, family = binomial, random = ~ 1 | block, data = df)
summary(glmm.mod2)
# The authors used proportional consumption of prey as the (y) in their model, but did not include this in the dataset.
# So we are going to create it - run the following line, assuming df= your data frame (feel free to change that):
df$prop.cons <- df$eaten/df$prey
df$prop.cons
library("anytime")
install.packages("anytime")
library("anytime")
library("ggplot2")
data <- read.csv(file=("C:/GitHub/morgan/Week 7/Plankton_move_average.csv"), header=T)
data
head(data)
#Used the following lines to format the date and remove NAs from the dataset:
data$Date <- as.Date(data$Date, origin = "0001-01-01") # Setting values to "day zero".
data <- na.omit(data)
data
head(data)
#Plot these population data over time with the following code:
ggplot(data)  +
xlab("Numeric Date") + ylab("Density Individuals")+
geom_line(data=data, aes(Date, D.mendotae), color="black", alpha = 0.7, size=1)+
geom_line(data=data, aes(Date, LimncalanusF+LimncalanusM), color="orange",  alpha = 0.7, size=1)+ # adding males and females together, hint: this is actually spelled Limnocalanus
geom_line(data=data, aes(Date, Bythotrephes), color="sky blue",  alpha = 0.7, size=1)+
geom_line(data=data, aes(Date, Bythotrephes), color="sky blue",  alpha = 0.7, size=1)+
theme_bw()
#Now copy/paste in the Lotka-Volterra function, plotting script, and load the "deSolve" package from the tutorial:
LotVmod <- function (Time, State, Pars) {
with(as.list(c(State, Pars)), {
dx = x*(alpha - beta*y)
dy = -y*(gamma - delta*x)
return(list(c(dx, dy)))
})
}
Pars <- c(alpha = 2, beta = 0.5, gamma = .2, delta = .6) #This is the line we will change
State <- c(x = 10, y = 10)#For now keep this the same.
Time <- seq(0, 100, by = 1)#For now keep this the same.
#Now copy/paste in the Lotka-Volterra function, plotting script, and load the "deSolve" package from the tutorial:
LotVmod <- function (Time, State, Pars) {
with(as.list(c(State, Pars)), {
dx = x*(alpha - beta*y)
dy = -y*(gamma - delta*x)
return(list(c(dx, dy)))
})
}
library(deSolve)
# Population growth over time in isolation ####
library("growthrates")
# This is an example dataset from the growthrates package.
data(bactgrowth)
# Most important for us, these data include bacterial strain, density, and antibiotic concentration (Tetracycline) through time.
# The following lines will process these data to structure them to be read by the all_growthmodels() function.
# This pre-processing of the data follows the example from ?all_growthmodels:
splitted.data <- multisplit(value ~ time | strain + conc + replicate,
data = bactgrowth)
# Show which experiments are in splitted.data
names(splitted.data)
# Get table from single experiment
dat <- splitted.data[["D:0:1"]]
fit0 <- fit_spline(dat$time, dat$value)
fit1 <- all_splines(value ~ time | strain + conc + replicate,
data = bactgrowth, spar = 0.5)
# These examples require some CPU power and may take a bit longer
# Initial parameters
p <- c(coef(fit0), K = max(dat$value))
# avoid negative parameters
lower = c(y0 = 0, mumax = 0, K = 0)
# Now we will look at the population growth models for all strains.
all_mods <- all_growthmodels(
value ~ grow_logistic(time, parms) | strain + conc,
data = bactgrowth, p = p, lower = lower, ncores = 2)
plot(all_mods)
# Extract the observations from the model fits - this is an "S4" object. We have only worked with "S3" objects so far.
# S4 allows for a more complicated data structure that is pre-defined and creates "slots" for objects within the listed larger object.
# These are called with the "@" symbol instead of a "$".
# We can use the slot() function to subset the object.
fits_slot <- slot(all_mods, "fits")
subset_obs <- slot(fits_slot$`R:250`, "obs")
# Or you can call the vector, data frame, or other info directly through a combo of "@" and "$" depending on the object structure.
# In our case it's extra complicated and includes a nested S4 object, hence the two @ symbols.
# This will give you the same result as the slot() function from above.
R250_obs <- all_mods@fits$`R:250`@obs
# You can confirm if they match through a quick logical:
table(subset_obs==R250_obs)
# You can also call the slot directly inside of a plot:
plot(all_mods@fits$`R:250`@obs)
# To look at all 6 plots we are interested in we'll create a multipanel plot.
# This use of par() will plot 2 rows with 3 plots in each row:
par(mfrow = c(2, 3))
plot(all_mods@fits$`R:250`@obs)
plot(all_mods@fits$`T:125`@obs)
plot(all_mods@fits$`R:125`@obs)
plot(all_mods@fits$`D:62.5`@obs)
plot(all_mods@fits$`D:1.95`@obs)
plot(all_mods@fits$`D:0.24`@obs)
par(mfrow = c(2, 3))
plot(all_mods@fits$`R:250`@obs, ylim = c(0.01,0.09))
plot(all_mods@fits$`T:125`@obs, ylim = c(0.01,0.09))
plot(all_mods@fits$`R:125`@obs, ylim = c(0.01,0.09))
plot(all_mods@fits$`D:62.5`@obs, ylim = c(0.01,0.09))
plot(all_mods@fits$`D:1.95`@obs, ylim = c(0.01,0.09))
plot(all_mods@fits$`D:0.24`@obs, ylim = c(0.01,0.09))
#Code from: https://www.r-bloggers.com/lotka-volterra-model%C2%A0%C2%A0intro/
library(deSolve)
# To create these plots and view in the full window, we need to remove the par() settings for multipanel plots.
# This is done with the dev.off() function
dev.off()
LotVmod <- function (Time, State, Pars) {
with(as.list(c(State, Pars)), {
dx = x*(alpha - beta*y)
dy = -y*(gamma - delta*x)
return(list(c(dx, dy)))
})
}
Pars <- c(alpha = 2, beta = 0.5, gamma = .2, delta = .6) #This is the line we will change
State <- c(x = 10, y = 10)#For now keep this the same.
Time <- seq(0, 100, by = 1)#For now keep this the same.
out <- as.data.frame(ode(func = LotVmod, y = State, parms = Pars, times = Time)) #This is the operation that creates the Lotka-Volterra model based on our specified parameters.
#The next two lines plot the model with the predator and prey against each other.
matplot(out[,-1], type = "l", xlab = "time", ylab = "population")
legend("topright", c("Rabid foxes", "Cute bunnies"), lty = c(1,2), col = c(1,2), box.lwd = 0)
head(data)
#Plot these population data over time with the following code:
ggplot(data)  +
xlab("Numeric Date") + ylab("Density Individuals")+
geom_line(data=data, aes(Date, D.mendotae), color="black", alpha = 0.7, size=1)+
geom_line(data=data, aes(Date, LimncalanusF+LimncalanusM), color="orange",  alpha = 0.7, size=1)+ # adding males and females together, hint: this is actually spelled Limnocalanus
geom_line(data=data, aes(Date, Bythotrephes), color="sky blue",  alpha = 0.7, size=1)+
geom_line(data=data, aes(Date, Bythotrephes), color="sky blue",  alpha = 0.7, size=1)+
theme_bw()
#Now copy/paste in the Lotka-Volterra function, plotting script, and load the "deSolve" package from the tutorial:
LotVmod <- function (Time, State, Pars) {
with(as.list(c(State, Pars)), {
dx = x*(alpha - beta*y)
dy = -y*(gamma - delta*x)
return(list(c(dx, dy)))
})
}
Pars <- c(alpha = 2, beta = 0.5, gamma = .2, delta = .6) #This is the line we will change
State <- c(x = 10, y = 10)#For now keep this the same.
Time <- seq(0, 100, by = 1)#For now keep this the same.
out <- as.data.frame(ode(func = LotVmod, y = State, parms = Pars, times = Time))
matplot(out[,-1], type = "l", xlab = "Numeric Date", ylab = "Density Individuals")
legend("topright", c("D. mendotae", "Limnocalanus"), lty = c(1,2), col = c(1,2), box.lwd = 0)
#Now copy/paste in the Lotka-Volterra function, plotting script, and load the "deSolve" package from the tutorial:
LotVmod <- function (Time, State, Pars) {
with(as.list(c(State, Pars)), {
dx = x*(alpha - beta*y)
dy = -y*(gamma - delta*x)
return(list(c(dx, dy)))
})
}
Pars <- c(alpha = 2, beta = 0.7, gamma = .2, delta = .6) #This is the line we will change
State <- c(x = 10, y = 10)#For now keep this the same.
Time <- seq(0, 100, by = 1)#For now keep this the same.
out <- as.data.frame(ode(func = LotVmod, y = State, parms = Pars, times = Time))
matplot(out[,-1], type = "l", xlab = "Numeric Date", ylab = "Density Individuals")
legend("topright", c("D. mendotae", "Limnocalanus"), lty = c(1,2), col = c(1,2), box.lwd = 0)
matplot(out[,-1], type = "l", xlab = "Numeric Date", ylab = "Density Individuals")
legend("topright", c("D. mendotae", "Limnocalanus"), lty = c(1,2), col = c(1,2), box.lwd = 0)
matplot(out[,-1], type = "l", xlab = "Numeric Date", ylab = "Density Individuals")
data <- read.csv(file=("C:/GitHub/morgan/Week 7/Plankton_move_average.csv"), header=T)
data
head(data)
#Used the following lines to format the date and remove NAs from the dataset:
data$Date <- as.Date(data$Date, origin = "0001-01-01") # Setting values to "day zero".
data <- na.omit(data)
data
head(data)
#Plot these population data over time with the following code:
ggplot(data)  +
xlab("Numeric Date") + ylab("Density Individuals")+
geom_line(data=data, aes(Date, D.mendotae), color="black", alpha = 0.7, size=1)+
geom_line(data=data, aes(Date, LimncalanusF+LimncalanusM), color="orange",  alpha = 0.7, size=1)+ # adding males and females together, hint: this is actually spelled Limnocalanus
geom_line(data=data, aes(Date, Bythotrephes), color="sky blue",  alpha = 0.7, size=1)+
geom_line(data=data, aes(Date, Bythotrephes), color="sky blue",  alpha = 0.7, size=1)+
theme_bw()
#Now copy/paste in the Lotka-Volterra function, plotting script, and load the "deSolve" package from the tutorial:
LotVmod <- function (Time, State, Pars) {
with(as.list(c(State, Pars)), {
dx = x*(alpha - beta*y)
dy = -y*(gamma - delta*x)
return(list(c(dx, dy)))
})
}
Pars <- c(alpha = 2, beta = 0.7, gamma = .2, delta = .6) #This is the line we will change
State <- c(x = 10, y = 10)#For now keep this the same.
Time <- seq(0, 100, by = 1)#For now keep this the same.
out <- as.data.frame(ode(func = LotVmod, y = State, parms = Pars, times = Time))
matplot(out[,-1], type = "l", xlab = "Numeric Date", ylab = "Density Individuals")
legend("bottomleft", c("D. mendotae", "Limnocalanus"), lty = c(1,2), col = c(1,2), box.lwd = 0)
Pars <- c(alpha = 1, beta = 0.9, gamma = .3, delta = .6) #This is the line we will change
#Now copy/paste in the Lotka-Volterra function, plotting script, and load the "deSolve" package from the tutorial:
LotVmod <- function (Time, State, Pars) {
with(as.list(c(State, Pars)), {
dx = x*(alpha - beta*y)
dy = -y*(gamma - delta*x)
return(list(c(dx, dy)))
})
}
Pars <- c(alpha = 1, beta = 0.9, gamma = .3, delta = .6) #This is the line we will change
State <- c(x = 10, y = 10)#For now keep this the same.
Time <- seq(0, 100, by = 1)#For now keep this the same.
out <- as.data.frame(ode(func = LotVmod, y = State, parms = Pars, times = Time))
matplot(out[,-1], type = "l", xlab = "Numeric Date", ylab = "Density Individuals")
legend("bottomleft", c("D. mendotae", "Limnocalanus"), lty = c(1,2), col = c(1,2), box.lwd = 0)
legend("topright", c("D. mendotae", "Limnocalanus"), lty = c(1,2), col = c(1,2), box.lwd = 0)
matplot(out[,-1], type = "l", xlab = "Numeric Date", ylab = "Density Individuals")
legend("topright", c("D. mendotae", "Limnocalanus"), lty = c(1,2), col = c(1,2), box.lwd = 0)
matplot(out[,-1], type = "l", xlab = "Numeric Date", ylab = "Density Individuals")
# First things first, load the vegan library.
# Any time you are looking at community ecology, the package is probably going to be vegan.
library(vegan)
# We will use the "dune" dataset from vegan.
# the dune data are plant communities from dune meadows.
data(dune)
# There is also a data frame of environmental factors that match the dune plants that we will use this week:
data(dune.env)
# We are focusing on Redundancy Analysis (RDA).
# But all of these methods can be transferred to other multivariate techniques very easily.
# pca() and cca() can typically just replace the rda() in any of these functions and models.
# The generic use of rda is very straightforward. All you need is a numeric species-by-site matrix.
dune #to see what I mean by a species-by-site matrix
ord <- rda(dune)
plot(ord)
# The real power of RDA is the ability to explain variance via a model.
# We'll use the dune.env data and take a quick look first to see type of data are included:
head(dune.env)
# Agriculture use typically impacts plant communities, so we will start there.
# This should look very familiar to the model syntax we have used so far.
mod1 <- rda(dune ~ Use, dune.env)
mod1
#The model call gives us constrained and unconstrained variance
# Constrained is the percent of the axes that is explained by "Use"
# Unconstrained is similar to the residuals of a linear model.
# We can also call the anova() function the same way that you would for a linear model:
anova(mod1)
# Moisture is another common driver of plant community composition
mod2 <- rda(dune ~ Moisture, dune.env)
mod2
anova(mod2)
# Just like other models, we can include additive or interactive effects as well:
# We can see what the cumulative effect of management and soil moisture is on the plant community:
mod3 <- rda(dune ~ Moisture + Management, dune.env)
mod3
anova(mod3)
#Let's plot to see what this looks like visually:
plot(mod3)
# Because of the amount of information, ordination plots are best done in layers, like adding regression lines.
# First create a blank plot where the axes are auto-fitted to the min and max values of "mod3"
plot(mod3, type="n", display = c("sites", "scores"))
# Next we will add a layer where the points are displayed with a label that represents their management
text(mod3, display="sites", labels = as.character(dune.env$Management))
# It looks like the same management types are grouping together.
# We would expect this based on our high variance explained and significant p-value.
# But statistically viewing this relationship can be difficult.
# We will draw 95% confidence intervals around the "centroid" (average score) for each management group.
# This is done with the ordiellipse() function. Notice there is an argument for the confidence interval and the grouping:
pl <- ordiellipse(mod3, dune.env$Management, kind="se", conf=0.95, lwd=2, draw = "polygon",
col="skyblue", border = "blue")
summary(pl)
# We can also group data by a factor that was not in the model to identify more complex patterns:
# We can see if the "Use" influences the communities that are already constrained by "Management":
plot(mod3, type="n", display = "sites")
text(mod3, display="sites", labels = as.character(dune.env$Use))
pl <- ordiellipse(mod3, dune.env$Use, kind="se", conf=0.95, lwd=2, draw = "polygon",
col="skyblue", border = "blue")
summary(pl)
# We can try plotting against a different axis to see if this is simply a weaker pattern obscured by Axis 1
# This requires a little data manipulation as plot() does not like to use other axes from default.
# First we need to extract the axis scores from the model
# These are found in the following two parts of the model:
Site_Scores <- mod3$CCA$u
Species_Scores <- mod3$CCA$v
head(Site_Scores)
plot(Site_Scores[,2:3], type="n")
text(Site_Scores[,2:3], labels = as.character(dune.env$Use))
pl <- ordiellipse(Site_Scores[,2:3], dune.env$Use, kind="se", conf=0.95, lwd=2, draw = "polygon",
col="skyblue", border = "blue")
rarefaction<-function(x,subsample=5, plot=TRUE, color=TRUE, error=FALSE, legend=TRUE, symbol=c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18)){
library(vegan)
x <- as.matrix(x)
y1<-apply(x, 1, sum)
rare.data<-x
select<-unique(sort(c((apply(x, 1, sum)), (seq(0,(max(y1)), by=subsample)), recursive=TRUE)))
storesummary.e<-matrix(data=NA, ncol=length(rare.data[,1]),nrow=length(select))
rownames(storesummary.e)<-c(select)
colnames(storesummary.e)<-rownames(x)
storesummary.se<-matrix(data=NA, ncol=length(rare.data[,1]),nrow=length(select))
rownames(storesummary.se)<-c(select)
colnames(storesummary.se)<-rownames(x)
for(i in 1:length(select))                      #the for loop
{
select.c<-select[i]                     #assigns the 'i'th element of select to select.c
foo<-rarefy(x,select.c, se=T)           #use whatever vegan fn you want
storesummary.e[i,]<-foo[1,]
storesummary.se[i,]<-foo[2,]
}
storesummary.e<-as.data.frame(storesummary.e)
richness.error<<-storesummary.se
for (i in 1:(length(storesummary.e)))
{
storesummary.e[,i]<-ifelse(select>sum(x[i,]), NA, storesummary.e[,i])
}
###############plot result################################
if (plot==TRUE)
{
if(color==TRUE){
plot(select,storesummary.e[,1], xlab="Individuals in Subsample",
xlim=c(0,max(select)), ylim=c(0, 5+(max(storesummary.e[,1:(length(storesummary.e))], na.rm=TRUE))),
ylab="Mean Species Richness", pch =16, col=2, type="n")
for (j in 1:(length(storesummary.e))){
points(select, storesummary.e[,j], pch=16, col=j+1, type="b", lty=1)}
if(error==TRUE){
for (m in 1:(length(storesummary.e))){
segments(select, storesummary.e[,m]+storesummary.se[,m],select, storesummary.e[,m]-storesummary.se[,m])
}
}
if (legend==TRUE){
legend("bottomright", colnames(storesummary.e), inset=0.05, lty=1, col=1:length(storesummary.e)+1, lwd=2)
}
}
else
{
plot(select,storesummary.e[,1], xlab="Individuals in Subsample",
xlim=c(0,max(select)), ylim=c(0, 5+(max(storesummary.e[,1:(length(storesummary.e))], na.rm=TRUE))),
ylab="Mean Species Richness", pch =16, col=2, type="n")
for (j in 1:(length(storesummary.e))){
points(select, storesummary.e[,j], type="l", lty=1)}
for (k in 1:(length(storesummary.e))){
symbol<-ifelse(symbol<length(storesummary.e),rep(symbol,2),symbol)
points(as.numeric(rownames(subset(storesummary.e, storesummary.e[,k]==max(storesummary.e[,k],na.rm=TRUE)))), max(storesummary.e[,k],na.rm=TRUE), pch=symbol[k], cex=1.5)}
if(error==TRUE){
for (m in 1:(length(storesummary.e))){
points(select, storesummary.e[,m]+storesummary.se[,m], type="l", lty=2)
points(select, storesummary.e[,m]-storesummary.se[,m], type="l", lty=2)}}
k<-1:(length(storesummary.e))
if (legend==TRUE){
legend("bottomright", colnames(storesummary.e), pch=symbol[k], inset=0.05, cex=1.3)
}
}
}
print("rarefaction by J. Jacobs, last update April 17, 2009")
if(error==TRUE)(print("errors around lines are the se of the iterations, not true se of the means")  )
list("richness"= storesummary.e, "SE"=richness.error, "subsample"=select)
}
# We are using the "BCI" data from vegan for the example:
data(BCI)
# First take a look at the data:
head(BCI)
rarefaction(BCI, subsample=50, plot=TRUE, color=TRUE, error=FALSE,  legend=TRUE, symbol)
samples <- as.data.frame(t(rowSums(t(BCI))))
rarefaction(samples, subsample=500, plot=TRUE, color=TRUE, error=FALSE,  legend=TRUE, symbol)
# What if you want to collect just a few larger samples?
rarefaction(samples, subsample=5000, plot=TRUE, color=TRUE, error=FALSE,  legend=TRUE, symbol)
library(readxl)
Data_rabbit_abund_motorway_Dryad <- read_excel("Week 8/Data_rabbit abund motorway_Dryad.xlsx")
View(Data_rabbit_abund_motorway_Dryad)
setwd("C:/GitHub/morgan/Final Project")
library(readxl)
#Reading in the soil temperature excel dataset and making it into a data frame.
soiltemp.tibble <- read_excel("KY Soil Data.xlsx")
soiltemp <- as.data.frame(soiltemp.tibble)
head(soiltemp)
#Reading in the arthropod and rainfall excel dataset and making it into a data frame.
arthrain.tibble <- read_excel("Wise_DH_Lensing_JR_2019.xlsx")
arthrain <- as.data.frame(arthrain.tibble)
#Merging the two datasets based on the period of sample collection and rounding the temperature values to integers.
df <- merge(soiltemp, arthrain, by = "period")
df$roundmaxtemp <- format(round(df$avgmaxtemp, 0), nsmall = 0)
df$roundmintemp <- format(round(df$avgmintemp, 0), nsmall = 0)
library(spdep)
library(adespatial)
library(vegan)
#Converting the excel data files into csv files to be used in RDA analyses.
KY_Soil_Data.csv <- read.csv("KY_Soil_Data.csv", header=T)
Wise_DH_Lensing_JR_2019.csv <- read.csv("Wise_DH_Lensing_JR_2019.csv", header=T)
KY_Soil_Data.mat <- as.matrix(KY_Soil_Data.csv)
Wise_DH_Lensing_JR_2019.mat <- as.matrix(Wise_DH_Lensing_JR_2019.csv)
#Soil Temperature Controlling Arthropods
soiltemp.rda <- rda(df[,9:89]~avgmaxtemp + avgmintemp, data=df)
soiltemp.rda
RsquareAdj(soiltemp.rda)
anova(soiltemp.rda, perm.max = 10000)
summary(soiltemp.rda)
plot(soiltemp.rda)
plot(soiltemp.rda, type = "n", ylim = c(1,2), display = c("sites", "species"), main = "Soil Temperature and Arthropods", xlab = "RDA1 (28.2%)", ylab = "RDA2 (1.02%)")
text(soiltemp.rda, display = "sites", labels = as.numeric(df$roundmintemp, df$roundmaxtemp), col = "blue3", cex = 0.65)
text(soiltemp.rda, display = "species", labels = as.character(colnames(df[,9:89])), col = "darkmagenta", cex = 0.65)
#Rainfall Controlling Arthropods
rainfall.rda <- rda(df[,9:89]~trt, data=df)
rainfall.rda
RsquareAdj(rainfall.rda)
anova(rainfall.rda, perm.max = 10000)
summary(rainfall.rda)
plot(rainfall.rda)
plot(rainfall.rda, type = "n", ylim = c(1,2), display = c("sites", "species"), main = "Rainfall and Arthropods", xlab = "RDA1 (8.15%)", ylab = "RDA2 (0.800%)")
text(rainfall.rda, display = "sites", labels = as.character(df$trt), col = "blue3", cex = 0.65)
text(rainfall.rda, display = "species", labels = as.character(colnames(df[,9:89])), col = "darkmagenta", cex = 0.65)
library(MASS)
library(MuMIn)
library(mgcv)
glm.Khypo <- glm(Khypo~trt + avgmaxtemp + avgmintemp, family = gaussian, data = df)
summary(glm.Khypo)
plot(glm.Khypo$residuals)
gam.Khypo <- gam(Khypo~trt + avgmaxtemp * avgmintemp, family = poisson, data = df)
summary(gam.Khypo)
plot(gam.Khypo$residuals)
AIC(gam.Khypo)
hist(df$Khypo, breaks = 50)
glm.Kacarina <- glm(Khypo~trt + avgmaxtemp + avgmintemp, family = poisson, data = df)
summary(glm.Kacarina)
plot(glm.Kacarina$residuals)
gam.Kacarina <- gam(Kacarina~trt + avgmaxtemp * avgmintemp, family = gaussian, data = df)
summary(gam.Kacarina)
plot(gam.Kacarina$residuals)
AIC(gam.Kacarina)
hist(df$Kacarina) #Normal distribution?
#Creating a linear model for Acarina as this was the species found to be most significantly impacted by soil temperature.
plot(Kacarina~avgmaxtemp, data = df, main = "Acarina (Kempson Sample)", xlab = "Average Maximum Soil Temperature (Degrees F)", ylab = "Density of Individuals")
plot(Kacarina~avgmintemp, data = df, main = "Acarina (Kempson Sample)", xlab = "Average Minimum Soil Temperature (Degrees F)", ylab = "Density of Individuals")
